{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS/x7lElrgJjaUBr07WtrP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vhyvean/alx-pre_course/blob/master/Web_Scraping_Wikipedia_Checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XyJuEHLSBELn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b46df16-4b58-433d-a933-90d70ad58ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article Title:\n",
            "Python (programming language)\n",
            "\n",
            "Headings and Paragraphs:\n",
            "\n",
            "Introduction:\n",
            "  - Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentatio...\n",
            "  - Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), ...\n",
            "\n",
            "History:\n",
            "  - Python was conceived in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands.[42] It was designed as a su...\n",
            "  - The name Python derives from the British comedy series Monty Python's Flying Circus.[47] (See § Naming.)...\n",
            "\n",
            "Design philosophy and features:\n",
            "  - Python is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of their feature...\n",
            "  - Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management.[62] It uses dynamic ...\n",
            "\n",
            "Syntax and semantics:\n",
            "  - Python is meant to be an easily readable language. Its formatting is visually uncluttered and often uses English keywords where other languages use pu...\n",
            "\n",
            "Indentation:\n",
            "  - Python uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statemen...\n",
            "\n",
            "Statements and control flow:\n",
            "  - Python's statements include the following:...\n",
            "  - The assignment statement (=) binds a name as a reference to a separate, dynamically allocated object. Variables may subsequently be rebound at any tim...\n",
            "\n",
            "Expressions:\n",
            "  - Python's expressions include the following:...\n",
            "  - In Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This d...\n",
            "\n",
            "Typing:\n",
            "  - Python uses duck typing, and it has typed objects but untyped variable names. Type constraints are not checked at definition time; rather, operations ...\n",
            "  - Python allows programmers to define their own types using classes, most often for object-oriented programming. New instances of classes are constructe...\n",
            "\n",
            "Arithmetic operations:\n",
            "  - Python includes conventional symbols for arithmetic operators (+, -, *, /), the floor-division operator //, and the modulo operator %. (With the modul...\n",
            "  - Division between integers produces floating-point results. The behavior of division has changed significantly over time:[105]...\n",
            "\n",
            "Function syntax:\n",
            "  - Functions are created in Python by using the def keyword. A function is defined similarly to how it is called, by first providing the function name an...\n",
            "  - To assign a default value to a function parameter in case no actual value is provided at run time, variable-definition syntax can be used inside the f...\n",
            "\n",
            "Code examples:\n",
            "  - \"Hello, World!\" program:...\n",
            "  - Program to calculate the factorial of a positive integer:...\n",
            "\n",
            "Libraries:\n",
            "  - Python's large standard library[115] is commonly cited as one of its greatest strengths. For Internet-facing applications, many standard formats and p...\n",
            "  - Some parts of the standard library are covered by specifications—for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows P...\n",
            "\n",
            "Development environments:\n",
            "  - Most[which?] Python implementations (including CPython) include a read–eval–print loop (REPL); this permits the environment to function as a command l...\n",
            "  - Python is also bundled with an integrated development environment (IDE) called IDLE,[119] which is oriented toward beginners.[citation needed]...\n",
            "\n",
            "Implementations:\n",
            "\n",
            "Reference implementation:\n",
            "  - CPython is the reference implementation of Python. This implementation is written in C, meeting the C11 standard[124] since version 3.11. Older versio...\n",
            "  - CPython is available for many platforms, including Windows and most modern Unix-like systems, including macOS (and Apple M1 Macs, since Python 3.9.1, ...\n",
            "\n",
            "Other implementations:\n",
            "  - All alternative implementations have at least slightly different semantics. For example, an alternative may include unordered dictionaries, in contras...\n",
            "\n",
            "Unsupported implementations:\n",
            "  - Stackless Python is a significant fork of CPython that implements microthreads. This implementation uses the call stack differently, thus allowing mas...\n",
            "  - Just-in-time Python compilers have been developed, but are now unsupported:...\n",
            "\n",
            "Cross-compilers to other languages:\n",
            "  - There are several compilers/transpilers to high-level object languages; the source language is unrestricted Python, a subset of Python, or a language ...\n",
            "  - There are also specialized compilers:...\n",
            "\n",
            "Performance:\n",
            "  - A performance comparison among various Python implementations, using a non-numerical (combinatorial) workload, was presented at EuroSciPy '13.[160] In...\n",
            "  - There are several approaches to optimizing Python performance, given the inherent slowness of an interpreted language. These approaches include the fo...\n",
            "\n",
            "Language Development:\n",
            "  - Python's development is conducted largely through the Python Enhancement Proposal (PEP) process; this process is the primary mechanism for proposing m...\n",
            "  - Enhancement of the language corresponds with development of the CPython reference implementation. The mailing list python-dev is the primary forum for...\n",
            "\n",
            "Naming:\n",
            "  - Python's name is inspired by the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty ...\n",
            "  - The affix Py is often used when naming Python applications or libraries. Some examples include the following:...\n",
            "\n",
            "See also:\n",
            "\n",
            "External links:\n",
            "\n",
            "Notes:\n",
            "\n",
            "References:\n",
            "  - Cite error: A list-defined reference named \"quotes-about-python\" is not used in the content (see the help page).\n",
            "Cite error: A list-defined reference ...\n",
            "\n",
            "Sources:\n",
            "\n",
            "Further reading:\n",
            "\n",
            "Number of Internal Links Found: 629\n"
          ]
        }
      ],
      "source": [
        "import requests # Import the requests library for making HTTP requests\n",
        "from bs4 import BeautifulSoup # Import BeautifulSoup from the bs4 library for parsing HTML\n",
        "\n",
        "# 1. Function to get and parse HTML content from a wikipedia page\n",
        "def get_html_content(url): # Define a function to get and parse HTML content\n",
        "    \"\"\"\n",
        "    Fetches and parses the HTML content of a given Wikipedia page.\n",
        "    Returns a BeautifulSoup object representing the parsed HTML.\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36' # Define a User-Agent header to mimic a browser\n",
        "    }\n",
        "    response = requests.get(url, headers=headers) # Send a request to the wikipedia URL to get the page data\n",
        "    if response.status_code != 200: # Check if the request was successfull (200 means succes)\n",
        "        raise Exception(f\"Failed to fetch the page. Status code: {response.status_code}\") # Raise an error if it failed\n",
        "    soup = BeautifulSoup(response.text, 'html.parser') # Parse the HTML content using BeautifulSoup\n",
        "    return soup # Return the parsed HTML for further processing\n",
        "\n",
        "# 2. Function to extract the article title\n",
        "def extract_article_title(soup): # Define a function to extract the article title\n",
        "    \"\"\"\n",
        "    Extracts and returns the article title from the BeautifulSoup object.\n",
        "    \"\"\"\n",
        "    title = soup.find('h1', id=\"firstHeading\") # Find the <h1> tag with the id=\"firstHeading\" (the article title)\n",
        "    return title.text.strip() if title else \"No title found\" # If found, return the clean text, else, return a message\n",
        "\n",
        "# 3. Function to extract article texts with their headings\n",
        "def extract_texts_with_headings(soup): # Define a function to extract texts with their headings\n",
        "    \"\"\"\n",
        "    Extracts all paragraphs and maps them to their nearest headings.\n",
        "    Returns a dictionary: {heading: [list of paragraphs]}.\n",
        "    \"\"\"\n",
        "    content = soup.find('div', {\"id\": \"mw-content-text\"}) # Find the main content area of the wikipedia article\n",
        "    if not content: # Check if the content div was not found\n",
        "        return {} # Return an empty dictionary if content is not found\n",
        "\n",
        "    data = {} # Initialize an empty dictionary to store headings and paragraphs\n",
        "    current_heading = \"Introduction\" # Initialize the current heading to \"Introduction\"\n",
        "    data[current_heading] = [] # Create an empty list for the \"Introduction\" heading\n",
        "\n",
        "    for tag in content.find_all(['h2', 'h3', 'p'], recursive=True): # Loop through all tags (headings and paragraphs) in the content\n",
        "        if tag.name in ['h2', 'h3']: # Check if the tag is an h2 or h3 (a heading)\n",
        "            current_heading = tag.text.replace(\"[edit]\", \"\").strip() # Set the current heading to the text of the heading tag, removing \"[edit]\" and stripping whitespace\n",
        "            data[current_heading] = [] # Create an empty list for the new heading\n",
        "        elif tag.name == 'p': # Check if the tag is a p (a paragraph)\n",
        "            # Added 'paragraph =' to create a variable before accessing its attribute\n",
        "            paragraph = tag # Assign the current tag to the paragraph variable\n",
        "            paragraph_text = paragraph.text.strip() # Get the text of the paragraph and remove extra spaces\n",
        "            if paragraph_text: # Check if the paragraph text is not empty\n",
        "                data[current_heading].append(paragraph_text) # Append the paragraph text to the list for the current heading\n",
        "\n",
        "    return data # Return all headings with their corresponding paragraphs\n",
        "\n",
        "# 4. Function to collect internal Wikipedia links\n",
        "def extract_internal_links(soup): # Define a function to extract internal links\n",
        "    \"\"\"\n",
        "    Extracts all internal Wikipedia links (i.e., links starting with '/wiki/').\n",
        "    Returns a list of full URLs.\n",
        "    \"\"\"\n",
        "    base_url = \"https://en.wikipedia.org\" # The main wikipedia domain\n",
        "    links = [] # Create an empty list to store internal links\n",
        "\n",
        "    for a_tag in soup.find_all('a', href=True): # Find all <a> tags with an 'href' attribute\n",
        "        href = a_tag['href'] # Get the value of the 'href' attribute (the actual link)\n",
        "        if href.startswith('/wiki/') and not ':' in href: # Only collect links to wikipedia articles (skip special pages)\n",
        "            full_link = base_url + href # Combine the base URL with the relative link\n",
        "            links.append(full_link) # Add the complete link to the list\n",
        "\n",
        "    return list(set(links)) # Remove duplicates and return a list of unique internal links\n",
        "\n",
        "# 5. Function to consolidate all the above functions\n",
        "def extract_wikipedia_data(url): # Define a function to consolidate all extraction tasks\n",
        "  \"\"\"\n",
        "  Consolidates all extraction tasks:\n",
        "  - Fetch HTML\n",
        "  - Extract title\n",
        "  - Extract text with headings\n",
        "  - Extract internal links\n",
        "  Return a dictionary with all data\n",
        "  \"\"\"\n",
        "  soup = get_html_content(url) # Get the parsed the HTML content\n",
        "  title = extract_article_title(soup) # Extract the article title\n",
        "  texts_with_headings = extract_texts_with_headings(soup) # Extract texts and map it toheadings\n",
        "  internal_links = extract_internal_links(soup) # Extract all internal wikipedia links\n",
        "\n",
        "  result = { # Combine all extracted data into a single dictionary\n",
        "      'Title': title, # Add the title to the dictionary\n",
        "      'Content': texts_with_headings, # Add the content (headings and paragraphs) to the dictionary\n",
        "      'Internal Links': internal_links # Add the internal links to the dictionary\n",
        "  }\n",
        "\n",
        "  return result # Return the dictionary containing all extracted data\n",
        "\n",
        "# 6. Test the final function on a Wikipedia page\n",
        "if __name__ == \"__main__\": # Ensures the test only runs when you run this file directly\n",
        "  test_url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\" # Example wikipedia page to test with\n",
        "\n",
        "  data = extract_wikipedia_data(test_url) # Run our main function and get all data\n",
        "\n",
        "  print(\"Article Title:\") # Print a label for the article title\n",
        "  print(data[\"Title\"]) # Print the title of the wikipedia page\n",
        "\n",
        "  print(\"\\nHeadings and Paragraphs:\") # Print a label for headings and paragraphs\n",
        "  for heading, paragraphs in data[\"Content\"].items(): # Loop through the headings and their associated paragraphs\n",
        "      print(f\"\\n{heading}:\") # Print the current heading\n",
        "      for p in paragraphs[:2]: # Iterate through the first two paragraphs for each heading\n",
        "          print(f\"  - {p[:150]}...\") # Print the first 150 characters of each paragraph with an indentation\n",
        "\n",
        "  print(\"\\nNumber of Internal Links Found:\", len(data[\"Internal Links\"])) # Print the number of internal links found"
      ]
    }
  ]
}